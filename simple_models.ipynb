{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from efc import EnergyBasedFlowClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from anomaly_flow.utils.binary_processing import split_flag_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = \"NF-CSE-CIC-IDS2018-v2-DDoS\"\n",
    "CROSS_DATASET = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_netflow = {\n",
    "    \"IPV4_SRC_ADDR\":                \"object\",\n",
    "    \"L4_SRC_PORT\":                  \"float32\",\n",
    "    \"IPV4_DST_ADDR\":                \"object\",\n",
    "    \"L4_DST_PORT\":                  \"float32\",\n",
    "    \"PROTOCOL\":                     \"float32\",\n",
    "    \"L7_PROTO\":                     \"float64\",\n",
    "    \"IN_BYTES\":                     \"float32\",\n",
    "    \"IN_PKTS\":                      \"float32\",\n",
    "    \"OUT_BYTES\":                    \"float32\",\n",
    "    \"OUT_PKTS\":                     \"float32\",\n",
    "    \"TCP_FLAGS\":                    \"int32\",\n",
    "    \"CLIENT_TCP_FLAGS\":             \"int32\",\n",
    "    \"SERVER_TCP_FLAGS\":             \"int32\",\n",
    "    \"FLOW_DURATION_MILLISECONDS\":   \"float32\",\n",
    "    \"DURATION_IN\":                  \"float32\",\n",
    "    \"DURATION_OUT\":                 \"float32\",\n",
    "    \"MIN_TTL\":                      \"float32\",\n",
    "    \"MAX_TTL\":                      \"float32\",\n",
    "    \"LONGEST_FLOW_PKT\":             \"float32\",\n",
    "    \"SHORTEST_FLOW_PKT\":            \"float32\",\n",
    "    \"MIN_IP_PKT_LEN\":               \"float32\",\n",
    "    \"MAX_IP_PKT_LEN\":               \"float32\",\n",
    "    \"SRC_TO_DST_SECOND_BYTES\":      \"float64\",\n",
    "    \"DST_TO_SRC_SECOND_BYTES\":      \"float64\",\n",
    "    \"RETRANSMITTED_IN_BYTES\":       \"float32\",\n",
    "    \"RETRANSMITTED_IN_PKTS\":        \"float32\",\n",
    "    \"RETRANSMITTED_OUT_BYTES\":      \"float32\",\n",
    "    \"RETRANSMITTED_OUT_PKTS\":       \"float32\",\n",
    "    \"SRC_TO_DST_AVG_THROUGHPUT\":    \"float32\",\n",
    "    \"DST_TO_SRC_AVG_THROUGHPUT\":    \"float32\",\n",
    "    \"NUM_PKTS_UP_TO_128_BYTES\":     \"float32\",\n",
    "    \"NUM_PKTS_128_TO_256_BYTES\":    \"float32\",\n",
    "    \"NUM_PKTS_256_TO_512_BYTES\":    \"float32\",\n",
    "    \"NUM_PKTS_512_TO_1024_BYTES\":   \"float32\",\n",
    "    \"NUM_PKTS_1024_TO_1514_BYTES\":  \"float32\",\n",
    "    \"TCP_WIN_MAX_IN\":               \"float32\",\n",
    "    \"TCP_WIN_MAX_OUT\":              \"float32\",\n",
    "    \"ICMP_TYPE\":                    \"float32\",\n",
    "    \"ICMP_IPV4_TYPE\":               \"float32\",\n",
    "    \"DNS_QUERY_ID\":                 \"float32\",\n",
    "    \"DNS_QUERY_TYPE\":               \"float32\",\n",
    "    \"DNS_TTL_ANSWER\":               \"float32\",\n",
    "    \"FTP_COMMAND_RET_CODE\":         \"float32\",\n",
    "    \"Attack\":                       \"object\",\n",
    "    \"Label\":                        \"float32\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TO_DROP = [\n",
    "    'IPV4_SRC_ADDR', \n",
    "    'IPV4_DST_ADDR', \n",
    "    'L7_PROTO', \n",
    "    'L4_SRC_PORT', \n",
    "    'L4_DST_PORT', \n",
    "    'FTP_COMMAND_RET_CODE',\n",
    "    'Attack'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    f\"./datasets/{TRAIN_DATASET}-downsample.csv.gz\",\n",
    "    dtype=dtypes_netflow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478055 entries, 0 to 478054\n",
      "Data columns (total 45 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   IPV4_SRC_ADDR                478055 non-null  object \n",
      " 1   L4_SRC_PORT                  478055 non-null  float32\n",
      " 2   IPV4_DST_ADDR                478055 non-null  object \n",
      " 3   L4_DST_PORT                  478055 non-null  float32\n",
      " 4   PROTOCOL                     478055 non-null  float32\n",
      " 5   L7_PROTO                     478055 non-null  float64\n",
      " 6   IN_BYTES                     478055 non-null  float32\n",
      " 7   IN_PKTS                      478055 non-null  float32\n",
      " 8   OUT_BYTES                    478055 non-null  float32\n",
      " 9   OUT_PKTS                     478055 non-null  float32\n",
      " 10  TCP_FLAGS                    478055 non-null  int32  \n",
      " 11  CLIENT_TCP_FLAGS             478055 non-null  int32  \n",
      " 12  SERVER_TCP_FLAGS             478055 non-null  int32  \n",
      " 13  FLOW_DURATION_MILLISECONDS   478055 non-null  float32\n",
      " 14  DURATION_IN                  478055 non-null  float32\n",
      " 15  DURATION_OUT                 478055 non-null  float32\n",
      " 16  MIN_TTL                      478055 non-null  float32\n",
      " 17  MAX_TTL                      478055 non-null  float32\n",
      " 18  LONGEST_FLOW_PKT             478055 non-null  float32\n",
      " 19  SHORTEST_FLOW_PKT            478055 non-null  float32\n",
      " 20  MIN_IP_PKT_LEN               478055 non-null  float32\n",
      " 21  MAX_IP_PKT_LEN               478055 non-null  float32\n",
      " 22  SRC_TO_DST_SECOND_BYTES      478055 non-null  float64\n",
      " 23  DST_TO_SRC_SECOND_BYTES      478055 non-null  float64\n",
      " 24  RETRANSMITTED_IN_BYTES       478055 non-null  float32\n",
      " 25  RETRANSMITTED_IN_PKTS        478055 non-null  float32\n",
      " 26  RETRANSMITTED_OUT_BYTES      478055 non-null  float32\n",
      " 27  RETRANSMITTED_OUT_PKTS       478055 non-null  float32\n",
      " 28  SRC_TO_DST_AVG_THROUGHPUT    478055 non-null  float32\n",
      " 29  DST_TO_SRC_AVG_THROUGHPUT    478055 non-null  float32\n",
      " 30  NUM_PKTS_UP_TO_128_BYTES     478055 non-null  float32\n",
      " 31  NUM_PKTS_128_TO_256_BYTES    478055 non-null  float32\n",
      " 32  NUM_PKTS_256_TO_512_BYTES    478055 non-null  float32\n",
      " 33  NUM_PKTS_512_TO_1024_BYTES   478055 non-null  float32\n",
      " 34  NUM_PKTS_1024_TO_1514_BYTES  478055 non-null  float32\n",
      " 35  TCP_WIN_MAX_IN               478055 non-null  float32\n",
      " 36  TCP_WIN_MAX_OUT              478055 non-null  float32\n",
      " 37  ICMP_TYPE                    478055 non-null  float32\n",
      " 38  ICMP_IPV4_TYPE               478055 non-null  float32\n",
      " 39  DNS_QUERY_ID                 478055 non-null  float32\n",
      " 40  DNS_QUERY_TYPE               478055 non-null  float32\n",
      " 41  DNS_TTL_ANSWER               478055 non-null  float32\n",
      " 42  FTP_COMMAND_RET_CODE         478055 non-null  float32\n",
      " 43  Label                        478055 non-null  float32\n",
      " 44  Attack                       478055 non-null  object \n",
      "dtypes: float32(36), float64(3), int32(3), object(3)\n",
      "memory usage: 93.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_df = pd.read_csv(\n",
    "    f\"./datasets/{CROSS_DATASET}-downsample.csv.gz\",\n",
    "    dtype=dtypes_netflow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.finfo(np.float32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack\n",
      "Benign            459044\n",
      "Exploits            6310\n",
      "Fuzzers             4462\n",
      "Generic             3312\n",
      "Reconnaissance      2556\n",
      "DoS                 1159\n",
      "Analysis             460\n",
      "Backdoor             434\n",
      "Shellcode            285\n",
      "Worms                 33\n",
      "Name: count, dtype: int64\n",
      "Using cached file: 2e1b49bdf7ef775ccf86409f36645a01.\n"
     ]
    }
   ],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(df['Attack'].value_counts())\n",
    "df.drop(FEATURES_TO_DROP, axis=1, inplace=True)\n",
    "df = df[df < threshold]\n",
    "df = split_flag_columns(df)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack\n",
      "Benign                    4990670\n",
      "DDOS attack-HOIC           324257\n",
      "DDoS attacks-LOIC-HTTP      92190\n",
      "DDOS attack-LOIC-UDP          634\n",
      "Name: count, dtype: int64\n",
      "Using cached file: 38e466053581bb706ccdb35435c58a35.\n"
     ]
    }
   ],
   "source": [
    "cross_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "cross_df.dropna(inplace=True)\n",
    "print(cross_df['Attack'].value_counts())\n",
    "cross_df.drop(FEATURES_TO_DROP, axis=1, inplace=True)\n",
    "cross_df = cross_df[cross_df < threshold]\n",
    "cross_df = split_flag_columns(cross_df)\n",
    "cross_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_x, cross_y = cross_df.drop(['Label', 'Unnamed: 0'], axis=1), cross_df['Label']\n",
    "\n",
    "X, y = df.drop(['Label'], axis=1), df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X, y, stratify=y,\n",
    "                                        test_size=0.33, random_state=42\n",
    "                                   )\n",
    "cross_x_train, cross_x_test, cross_y_train, cross_y_test = train_test_split(\n",
    "                                                                cross_x, cross_y,\n",
    "                                                                stratify=cross_y,\n",
    "                                                                test_size=0.9,\n",
    "                                                                random_state=42\n",
    "                                                           )\n",
    "\n",
    "# Reescale the models to train and test\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "cross_x_train = scaler.transform(cross_x_train)\n",
    "cross_x_test = scaler.transfor(cross_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids for each algorithm\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "param_grid_if = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'contamination': [0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 25), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'max_iter': [200, 300, 400],\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "}\n",
    "\n",
    "param_grid_lof = {\n",
    "    'contamination': [0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "}\n",
    "\n",
    "param_grid_efc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "lr_classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "if_classifier = IsolationForest(random_state=42)\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "mlp_classifier = MLPClassifier(random_state=42)\n",
    "svm_classifier = SVC(random_state=42)\n",
    "lof_classifier = LocalOutlierFactor(novelty=True)\n",
    "efc_classifier = EnergyBasedFlowClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of classifiers and their respective parameter grids\n",
    "classifiers = {\n",
    "    'Random Forest': (rf_classifier, param_grid_rf, 'f1', False),\n",
    "    'Logistic Regression': (lr_classifier, param_grid_lr, 'f1', False),\n",
    "    'Isolation Forest': (if_classifier, param_grid_if, 'roc_auc', True), \n",
    "    'eXtreme Gradient Boosting': (xgb_classifier, param_grid_xgb, 'f1', False),\n",
    "    'Multilayer Perceptron': (mlp_classifier, param_grid_mlp, 'f1', False),\n",
    "    # 'Support Vector Machine': (svm_classifier, param_grid_svm, 'f1', False),\n",
    "    # 'Local Outlier Factor': (lof_classifier, param_grid_lof, 'f1', False),\n",
    "    'Energy Based Flow Classifier': (efc_classifier, param_grid_efc, 'f1', False),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time= 1.3min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time= 1.7min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=50; total time= 2.0min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time= 2.4min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time= 4.5min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time= 3.5min\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time= 2.0min\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time= 1.5min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time= 4.6min\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=50; total time= 1.3min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time= 8.3min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time= 6.5min\n"
     ]
    }
   ],
   "source": [
    "result_file = dict()\n",
    "\n",
    "# Evaluate each classifier using GridSearchCV\n",
    "for classifier_name, (classifier, param_grid, metric, probability) in classifiers.items():\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        classifier,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring=metric,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and the corresponding accuracy on the test set\n",
    "    print(f\"Best parameters for {classifier_name}: {grid_search.best_params_}\")\n",
    "    result_file[classifier_name]['best_params'] = grid_search.best_params_\n",
    "\n",
    "    if probability is False:\n",
    "        # Make predictions on the test set\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        cross_pred = grid_search.predict(cross_x_test)\n",
    "\n",
    "        # Evaluate the performance on the same silo\n",
    "        accuracy_value = accuracy_score(y_test, y_pred)\n",
    "        f1_value = f1_score(y_test, y_pred)\n",
    "        f2_value = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "        print(f\"Accuracy on the test set: {accuracy_value:.4f}\")\n",
    "        print(f\"F1-Score on the test set: {f1_value:.4f}\")\n",
    "        print(f\"F2-Score on the test set: {f2_value:.4f}\")\n",
    "\n",
    "        result_file[classifier_name]['local_evaluation']['accuracy'] = accuracy_value\n",
    "        result_file[classifier_name]['local_evaluation']['f1_value'] = f1_value\n",
    "        result_file[classifier_name]['local_evaluation']['f2_value'] = f2_value\n",
    "\n",
    "        # Evaluate the performance on cross silos approach\n",
    "        accuracy_cross = accuracy_score(cross_y_test, cross_pred)\n",
    "        f1_cross = f1_score(cross_y_test, cross_pred)\n",
    "        f2_cross = fbeta_score(cross_y_test, cross_pred, beta=2)\n",
    "\n",
    "        print(f\"Accuracy on the cross-evaluation set: {accuracy_cross:.4f}\")\n",
    "        print(f\"F1-Score on the cross-evaluation set: {f1_cross:.4f}\")\n",
    "        print(f\"F2-Score on the cross-evaluation set: {f2_cross:.4f}\")\n",
    "\n",
    "        result_file[classifier_name]['cross_evaluation']['accuracy'] = accuracy_cross\n",
    "        result_file[classifier_name]['cross_evaluation']['f1_value'] = f1_cross\n",
    "        result_file[classifier_name]['cross_evaluation']['f2_value'] = f2_cross\n",
    "\n",
    "    elif probability is True:\n",
    "        anomaly_scores = grid_search.decision_function(X_test)\n",
    "\n",
    "        # Evaluate the perfomance on the local data samples\n",
    "        roc_auc = roc_auc_score(y_test, -anomaly_scores)\n",
    "        pr_auc = average_precision_score(y_test, -anomaly_scores)\n",
    "        print(f\"ROC AUC Score on the test set: {roc_auc:.4f}\")\n",
    "        print(f\"PR AUC Score on the test set: {pr_auc:.4f}\")\n",
    "\n",
    "        result_file[classifier_name]['local_evaluation']['roc_auc'] = roc_auc\n",
    "        result_file[classifier_name]['local_evaluation']['pr_auc'] = pr_auc\n",
    "\n",
    "        # Evaluate the performance on cross silos approach\n",
    "        anomaly_scores_cross = grid_search.decision_function(cross_x_test)\n",
    "        roc_auc = roc_auc_score(cross_y_test, -anomaly_scores_cross)\n",
    "        pr_auc = average_precision_score(cross_y_test, -anomaly_scores_cross)\n",
    "        print(f\"ROC AUC Score on the cross set: {roc_auc:.4f}\")\n",
    "        print(f\"PR AUC Score on the cross set: {pr_auc:.4f}\")\n",
    "\n",
    "        result_file[classifier_name]['cross_evaluation']['roc_auc'] = roc_auc\n",
    "        result_file[classifier_name]['cross_evaluation']['pr_auc'] = pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'simple_models_results'\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "    print(f\"Directory '{directory_path}' created.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_path}' already exists.\")\n",
    "\n",
    "file_path = f\"./simple_models_results/{TRAIN_DATASET}-{CROSS_DATASET}.json\"\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(result_file, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
